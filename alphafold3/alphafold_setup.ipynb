{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ec52ee4-f9f7-4446-b469-0af6d2e51112",
   "metadata": {},
   "source": [
    "In the first chunk you will write your base structure JSONs, input the PDB IDs of TCRs known to bind to the epitope generated for. The standard TCR chain notation is as follows:\n",
    "\n",
    "chain A: MHC\n",
    "chain B: Beta microglobulin\n",
    "chain C: peptide\n",
    "chain D: TCR alpha chain\n",
    "chain E: TCR beta chain\n",
    "\n",
    "Make sure that your base JSONs follow this structure!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed37cd-4c4a-4260-95f4-1618118dfdaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from Bio import SeqIO\n",
    "from io import StringIO\n",
    "\n",
    "def fetch_fasta(pdb_id):\n",
    "    \"\"\"Download FASTA for a PDB ID from RCSB and return SeqRecords.\"\"\"\n",
    "    url = f\"https://www.rcsb.org/fasta/entry/{pdb_id}\"\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != 200:\n",
    "        raise RuntimeError(f\"Failed to fetch FASTA for {pdb_id}\")\n",
    "    return list(SeqIO.parse(StringIO(r.text), \"fasta\"))\n",
    "\n",
    "def make_af3_json(pdb_id, outdir=\" \"):\n",
    "    \"\"\"Create AlphaFold3 JSON input using FASTA sequences.\"\"\"\n",
    "    records = fetch_fasta(pdb_id)\n",
    "\n",
    "    sequences = []\n",
    "    seen = set()\n",
    "    peptide_entry = None\n",
    "\n",
    "    for rec in records:\n",
    "        seq = str(rec.seq)\n",
    "        if seq in seen:\n",
    "            continue\n",
    "        seen.add(seq)\n",
    "\n",
    "        entry = {\"protein\": {\"sequence\": seq, \"description\": rec.description}}\n",
    "\n",
    "        # Identify peptide explicitly\n",
    "        if seq == \"GILGFVFTL\":\n",
    "            peptide_entry = entry\n",
    "        else:\n",
    "            sequences.append(entry)\n",
    "\n",
    "    # Force peptide to index 2 (third position)\n",
    "    if peptide_entry:\n",
    "        if len(sequences) >= 2:\n",
    "            sequences.insert(2, peptide_entry)\n",
    "        else:\n",
    "            sequences.append(peptide_entry)  # fallback if fewer than 2 entries\n",
    "    else:\n",
    "        print(f\"Warning: No peptide found for {pdb_id}\")\n",
    "\n",
    "    job = {\n",
    "        \"name\": f\"{pdb_id}_tcr_pmhc\",\n",
    "        \"modelSeeds\": [1],\n",
    "        \"sequences\": sequences,\n",
    "        \"dialect\": \"alphafold3\",\n",
    "        \"version\": 1\n",
    "    }\n",
    "\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    outfile = os.path.join(outdir, f\"{pdb_id}.json\")\n",
    "    with open(outfile, \"w\") as f:\n",
    "        json.dump(job, f, indent=2)\n",
    "\n",
    "    print(f\"Wrote JSON for {pdb_id}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdb_ids = [\"2vlj\", \"2vlk\", \"2vlr\", \"5isz\", \"1oga\", \"5euo\"] #fill IDs for epitope\n",
    "    for pdb_id in pdb_ids:\n",
    "        make_af3_json(pdb_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df27dcf-90ff-49c8-9ced-b64c0aa34b99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Input directories\n",
    "SOLVED_JSON_DIR = Path(\" \") # solved structures\n",
    "NEEDLEMEN_FILES = [] # see tcrdock/scripts for needlemen alignment script\n",
    "\n",
    "OUT_DIR = Path(\" \")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def load_json(pdb_id: str) -> dict:\n",
    "    path = SOLVED_JSON_DIR / f\"{pdb_id}.json\"\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Solved JSON not found: {path}\")\n",
    "    return json.loads(path.read_text())\n",
    "\n",
    "\n",
    "def replace_cdr3b(full_seq: str, old_cdr3: str, new_cdr3: str) -> str:\n",
    "    if old_cdr3 not in full_seq:\n",
    "        raise ValueError(f\"CDR3 {old_cdr3} not found in beta chain sequence\")\n",
    "    return full_seq.replace(old_cdr3, new_cdr3)\n",
    "\n",
    "\n",
    "def find_tcr_beta_entry(solved_json: dict) -> dict:\n",
    "    \"\"\"Return the 5th chain (index 4), assumed to be TCR beta.\"\"\"\n",
    "    try:\n",
    "        return solved_json[\"sequences\"][4][\"protein\"]\n",
    "    except IndexError:\n",
    "        raise KeyError(\"Solved JSON does not have at least 5 sequences (expected TCR beta at index 4)\")\n",
    "\n",
    "\n",
    "def process_needlemen(csv_file: str):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    prefix = get_prefix_from_path(csv_file)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        gen_idx = row[\"Generated_Index\"]\n",
    "        gen_cdr3 = row[\"Generated_TCR\"]\n",
    "        solved_id = row[\"Best_Solved_ID\"]\n",
    "        solved_cdr3 = row[\"Best_Solved_TCR\"]\n",
    "\n",
    "        solved_json = load_json(solved_id)\n",
    "\n",
    "        beta_protein = find_tcr_beta_entry(solved_json)\n",
    "        old_seq = beta_protein[\"sequence\"]\n",
    "\n",
    "        try:\n",
    "            new_seq = replace_cdr3b(old_seq, solved_cdr3, gen_cdr3)\n",
    "        except ValueError:\n",
    "            print(f\"WARNING: could not splice {gen_cdr3} into {solved_id} (index {gen_idx})\")\n",
    "            continue\n",
    "\n",
    "        beta_protein[\"sequence\"] = new_seq\n",
    "        solved_json[\"name\"] = f\"{prefix}_{gen_idx}\"\n",
    "\n",
    "        out_name = f\"{prefix}_{gen_idx}.json\"\n",
    "        out_path = OUT_DIR / out_name\n",
    "        out_path.write_text(json.dumps(solved_json, indent=2))\n",
    "\n",
    "        print(f\"Wrote {out_path}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    for f in NEEDLEMEN_FILES:\n",
    "        print(f\"Processing {f}\")\n",
    "        process_needlemen(f)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc4534-0e47-43a3-a5c1-eb4ed4a1fc3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Input directory containing your current JSONs\n",
    "input_dir = Path(\" \")\n",
    "# Output directory for cleaned version 1 JSONs\n",
    "output_dir = Path(\"\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Function to clean a single JSON\n",
    "def clean_json(json_path, output_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Set version to 1\n",
    "    data[\"version\"] = 1\n",
    "\n",
    "    # Ensure dialect is set\n",
    "    data[\"dialect\"] = \"alphafold3\"\n",
    "\n",
    "    # Remove unsupported fields in each sequence and fix IDs\n",
    "    new_sequences = []\n",
    "    for i, seq_entry in enumerate(data[\"sequences\"]):\n",
    "        seq_type = next(iter(seq_entry))  # 'protein', 'rna', 'dna', 'ligand'\n",
    "        seq_data = seq_entry[seq_type]\n",
    "\n",
    "        # Remove unsupported keys like 'description', 'templates', 'modifications', etc.\n",
    "        allowed_keys = {\"id\", \"sequence\", \"unpairedMsa\", \"pairedMsa\", \"ccdCodes\", \"smiles\"}\n",
    "        seq_data = {k: v for k, v in seq_data.items() if k in allowed_keys}\n",
    "\n",
    "        # Assign alphanumeric uppercase ID\n",
    "        seq_data[\"id\"] = chr(ord(\"A\") + i)\n",
    "\n",
    "        new_sequences.append({seq_type: seq_data})\n",
    "\n",
    "    data[\"sequences\"] = new_sequences\n",
    "\n",
    "    # Remove optional keys that version 1 does not support\n",
    "    for key in [\"bondedAtomPairs\", \"userCCD\", \"userCCDPath\"]:\n",
    "        if key in data:\n",
    "            data.pop(key)\n",
    "\n",
    "    # Write cleaned JSON\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "# Walk through input directory\n",
    "for json_file in input_dir.glob(\"*.json\"):\n",
    "    output_file = output_dir / json_file.name\n",
    "    clean_json(json_file, output_file)\n",
    "    print(f\"Cleaned {json_file.name} -> {output_file}\")\n",
    "\n",
    "print(\"All JSONs cleaned and written to\", output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c86d53-9682-4a98-9e98-e7b6e0d23da8",
   "metadata": {},
   "source": [
    "For controls, ambiguous amino acids codes can be found (X, B, Z, and J which can correspond to multiple amino acids in different frequencies), alphafold is unsure how to handle these so below, we will rewrite them randomly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6298096b-6fa6-4970-9180-30ab49d1bfcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# Natural amino acid frequencies\n",
    "aa_freqs = {\n",
    "    'A': 0.0825, 'R': 0.0553, 'N': 0.0406, 'D': 0.0545, 'C': 0.0137,\n",
    "    'Q': 0.0393, 'E': 0.0675, 'G': 0.0707, 'H': 0.0227, 'I': 0.0593,\n",
    "    'L': 0.0966, 'K': 0.0584, 'M': 0.0242, 'F': 0.0386, 'P': 0.0470,\n",
    "    'S': 0.0651, 'T': 0.0534, 'W': 0.0108, 'Y': 0.0292, 'V': 0.0687\n",
    "}\n",
    "\n",
    "def replace_ambiguous(seq):\n",
    "    new_seq = []\n",
    "    for aa in seq:\n",
    "        if aa == 'X':\n",
    "            new_seq.append(random.choices(list(aa_freqs.keys()), weights=aa_freqs.values())[0])\n",
    "        elif aa == 'B':\n",
    "            new_seq.append(random.choice(['D', 'N']))\n",
    "        elif aa == 'Z':\n",
    "            new_seq.append(random.choice(['E', 'Q']))\n",
    "        elif aa == 'J':\n",
    "            new_seq.append(random.choice(['I', 'L']))\n",
    "        else:\n",
    "            new_seq.append(aa)\n",
    "    return ''.join(new_seq)\n",
    "\n",
    "# Path to the list of JSONs\n",
    "json_list_file = Path(\" \")\n",
    "\n",
    "# Iterate over all JSON files in the list\n",
    "with open(json_list_file) as f:\n",
    "    for line in f:\n",
    "        json_path = Path(line.strip())\n",
    "        if not json_path.exists():\n",
    "            print(f\"File does not exist: {json_path}\")\n",
    "            continue\n",
    "\n",
    "        with json_path.open(\"r\") as jf:\n",
    "            data = json.load(jf)\n",
    "\n",
    "        updated = False\n",
    "        for entry in data.get(\"sequences\", []):\n",
    "            protein = entry.get(\"protein\", {})\n",
    "            if protein.get(\"id\") == \"E\":\n",
    "                original_seq = protein[\"sequence\"]\n",
    "                protein[\"sequence\"] = replace_ambiguous(original_seq)\n",
    "                updated = True\n",
    "                print(f\"Updated chain E in {json_path}\")\n",
    "                break\n",
    "\n",
    "        if updated:\n",
    "            with json_path.open(\"w\") as jf:\n",
    "                json.dump(data, jf, indent=2)\n",
    "        else:\n",
    "            print(f\"No chain E found in {json_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d4e1cd-7697-427e-b954-a54f96d13917",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db24614-a3b5-40c1-bd5c-02f8fa54ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "SOLVED_IDS = [\n",
    "    \"2vlj\", \"2vlk\", \"2vlr\", \"5euo\", \"5isz\", \"1oga\"\n",
    "]\n",
    "\n",
    "AF3_OUTPUT_DIR = Path(\" \")\n",
    "MSA_DIR = Path(\" \")\n",
    "MSA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for solved_id in SOLVED_IDS:\n",
    "    # Find output directory that starts with solved_id\n",
    "    dirs = [d for d in AF3_OUTPUT_DIR.iterdir() if d.is_dir() and d.name.startswith(solved_id)]\n",
    "    if not dirs:\n",
    "        print(f\"WARNING: No output dir found for {solved_id}, skipping\")\n",
    "        continue\n",
    "    out_dir = dirs[0]  # take the first match\n",
    "\n",
    "    data_json = out_dir / f\"{out_dir.name}_data.json\"\n",
    "    if not data_json.exists():\n",
    "        print(f\"WARNING: {data_json} not found, skipping\")\n",
    "        continue\n",
    "\n",
    "    with open(data_json) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    msa_solved_dir = MSA_DIR / solved_id\n",
    "    msa_solved_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for seq in data.get(\"sequences\", []):\n",
    "        prot = seq.get(\"protein\", {})\n",
    "        chain_id = prot.get(\"id\")\n",
    "        msa_content = prot.get(\"unpairedMsa\")\n",
    "        if not msa_content:\n",
    "            print(f\"No unpaired MSA for chain {chain_id} in {solved_id}\")\n",
    "            continue\n",
    "\n",
    "        msa_path = msa_solved_dir / f\"{chain_id}.a3m\"\n",
    "        with open(msa_path, \"w\") as msa_file:\n",
    "            msa_file.write(msa_content)\n",
    "\n",
    "        print(f\"Wrote MSA for {solved_id} chain {chain_id} -> {msa_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b8911-8a1d-45a7-befd-4a3dd878be8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MSA_DIR = Path(\"/scratch/ggrama/alphafold3/msa\")\n",
    "\n",
    "def sanitize_a3m(msa_path: Path):\n",
    "    lines = msa_path.read_text().splitlines()\n",
    "    if not lines:\n",
    "        return\n",
    "    # Uppercase the first sequence\n",
    "    lines[0] = lines[0].upper() if not lines[0].startswith(\">\") else lines[0]\n",
    "    sanitized_lines = []\n",
    "    for line in lines:\n",
    "        if line.startswith(\">\"):\n",
    "            sanitized_lines.append(line)\n",
    "        else:\n",
    "            sanitized_lines.append(line.upper().replace(\"-\", \"-\"))\n",
    "    msa_path.write_text(\"\\n\".join(sanitized_lines))\n",
    "\n",
    "for solved_id_dir in MSA_DIR.iterdir():\n",
    "    if not solved_id_dir.is_dir():\n",
    "        continue\n",
    "    for a3m_file in solved_id_dir.glob(\"*.a3m\"):\n",
    "        sanitize_a3m(a3m_file)\n",
    "        print(f\"Sanitized {a3m_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
